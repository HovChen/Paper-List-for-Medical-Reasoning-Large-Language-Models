<div id = "top"></div>

<div align="center">

[![](https://capsule-render.vercel.app/api?type=waving&height=170&color=0:5B83DE,100:6BCE9F&text=üåü%20Paper%20List%20for%20Medical%20Reasoning%20Large%20Language%20Models&fontSize=25&fontAlign=50&fontAlignY=35&fontColor=FFFFFF)
](#top)

</div>

<div align="center">
  

[![](https://img.shields.io/github/stars/HovChen/Paper-List-for-Medical-Reasoning-Large-Language-Models)](https://github.com/Medical-Reasoning-Large-Language-Models)
[![](https://img.shields.io/github/forks/HovChen/Paper-List-for-Medical-Reasoning-Large-Language-Models)](https://github.com/Medical-Reasoning-Large-Language-Models)
[![](https://img.shields.io/github/issues/HovChen/Paper-List-for-Medical-Reasoning-Large-Language-Models)](https://github.com/Medical-Reasoning-Large-Language-Models/issues)
[![](https://img.shields.io/github/license/HovChen/Paper-List-for-Medical-Reasoning-Large-Language-Models)](https://github.com/Medical-Reasoning-Large-Language-Models/blob/main/LICENSE) 
[![Visitors](https://api.visitorbadge.io/api/visitors?path=https%3A%2F%2Fgithub.com%2FHovChen%2FPaper-List-for-Medical-Reasoning-Large-Language-Models&label=visitors&countColor=%2337d67a&style=flat&labelStyle=none)](https://visitorbadge.io/status?path=https%3A%2F%2Fgithub.com%2FHovChen%2FPaper-List-for-Medical-Reasoning-Large-Language-Models)

</div>

**üßë‚Äçüíª Contributors: [Huangwei Chen (22' HDU Undergraduate)](https://hovchen.github.io/), [Zhenyu Yan (22' HDU Undergraduate)](https://github.com/Flartiny), [Yuqi Zhan (23' HDU Undergraduate)](https://github.com/Roin04), [Donghao Zhang (23' HDU Undergraduate)](https://github.com/ZDH520a), [Weihao Cheng (24' HDU Undergraduate)](https://github.com/code-11-lab), [Yueyi Wu (23' HDU Undergraduate)](https://github.com/Elsieeee3914), [Yifei Sun (22' HDU-ITMO Undergraduate)](https://diaoquesang.github.io/).**

**üîç DeepWiki: [Generating GitHub Knowledge Base Documentation in One Click ](https://deepwiki.com/HovChen/Paper-List-for-Medical-Reasoning-Large-Language-Models).**

**üì¶ Other resources: [1] [A Paper List for Medical Anomaly Detection](https://github.com/diaoquesang/Paper-List-for-Medical-Anomaly-Detection), [2] [A Paper List for Prototypical Learning](https://github.com/BeistMedAI/Paper-List-for-Prototypical-Learning).**

### Welcome to join us by contacting: chenhw@hdu.edu.cn.

<div style="text-align: center;">
<img src="logos/HDU.png" height="45px" href="https://www.hdu.edu.cn/">
</div>

## üìá Contents
- [**1. Language-Only Medical Reasoning Models**](#s1)
- [**2. Multimodal Medical Reasoning Models**](#s2)
- [**3. General Multimodal Reasoning Models**](#s3)

## 1. Language-Only Medical Reasoning Models <div id = "s1"></div>

1. [2504'arXiv] | Open-Medical-R1: How to Choose Data for RLVR Training at Medicine Domain | [`[paper]`](https://arxiv.org/abs/2504.13950) | [`[code]`](https://github.com/Qsingle/open-medical-r1)
2. [2505'arXiv] | Med-U1: Incentivizing Unified Medical Reasoning in LLMs via Large-scale Reinforcement Learning | [`[paper]`](https://arxiv.org/abs/2506.12307) | [`[code]`](https://github.com/Monncyann/Med-U1)
3. [2506'arXiv] | Med-PRM: Medical Reasoning Models with Stepwise, Guideline-verified Process Rewards | [`[paper]`](https://arxiv.org/abs/2506.11474) | [`[code]`](https://med-prm.github.io/)
4. [2501'Nature Medicine] | Toward expert-level medical questions answering with large language models | [`[paper]`](https://www.nature.com/articles/s41591-024-03423-7) | [`[code]`](https://cloud.google.com/vertex-ai/generative-ai/docs/medlm/overview)
5. [2506'arXiv] | ReasonMed: A 370K Multi-Agent Generated Dataset for Advancing Medical Reasoning | [`[paper]`](https://arxiv.org/abs/2506.09513) | [`[code]`](https://github.com/YuSun-Work/ReasonMed)
6. [2502'arXiv] | MedRAG: Enhancing Retrieval-augmented Generation with Knowledge Graph-Elicited Reasoning for Healthcare Copilot | [`[paper]`](https://arxiv.org/abs/2502.04413) | [`[code]`](https://github.com/SNOWTEAM2023/MedRAG)
7. [2401'arXiv] | Improving Medical Reasoning through Retrieval and Self-Reflection with Retrieval-Augmented Large Language Models| [`[paper]`](https://arxiv.org/abs/2401.15269v2) | [`[code]`](https://github.com/dmis-lab/self-biorag)

## 2. Multimodal Medical Reasoning Models <div id = "s2"></div>

1. [2505'arXiv] | Patho-R1: A Multimodal Reinforcement Learning-Based Pathology Expert Reasoner | [`[paper]`](https://arxiv.org/abs/2505.11404) | [`[code]`](https://github.com/Wenchuan-Zhang/Patho-R1)
2. [2503'arXiv] | Med-R1: Reinforcement Learning for Generalizable Medical Reasoning in Vision-Language Mode | [`[paper]`](https://arxiv.org/abs/2503.13939) | [`[code]`](https://github.com/Yuxiang-Lai117/Med-R1)
3. [2506'arXiv] | MedTVT-R1: A Multimodal LLM Empowering Medical Reasoning and Diagnosis | [`[paper]`](https://arxiv.org/abs/2506.18512) | [`[code]`](https://github.com/keke-nice/MedTVT-R1)
4. [2502'arXiv] | RadVLM: A Multitask Conversational Vision-Language Model for Radiology | [`[paper]`](https://arxiv.org/abs/2502.03333) | [`[code]`](https://huggingface.co/KrauthammerLab) 
5. [2504'arXiv] | MedReason: Eliciting Factual Medical Reasoning Steps in LLMs via Knowledge Graphs | [`[paper]`](https://arxiv.org/abs/2504.00993) | [`[code]`](https://github.com/UCSC-VLAA/MedReason) 
6. [2503'arXiv] | Reinforcement Learning for Generalizable Medical Reasoning in Vision-Language Models | [`[paper]`](https://arxiv.org/abs/2503.13939) 
7. [2502'arXiv] | MedVLM-R1: Incentivizing Medical Reasoning Capability of Vision-Language Models (VLMs) via Reinforcement Learning| [`[paper]`](https://arxiv.org/abs/2502.19634) | [`[code]`](https://huggingface.co/JZPeterPan/MedVLM-R1) 
8. [2504'arXiv] | ChestX-Reasoner: Advancing Radiology Foundation Models with Reasoning through Step-by-Step Verification| [`[paper]`](https://arxiv.org/abs/2504.20930) | [`[code]`](https://github.com/MAGIC-AI4Med/ChestX-Reasoner) 
9. [2504'arXiv] | GMAI-VL-R1: Harnessing Reinforcement Learning for Multimodal Medical Reasoning | [`[paper]`](https://arxiv.org/abs/2504.01886) | [`[code]`](https://github.com/uni-medical/GMAI-VL-R1?utm_source=catalyzex.com) 
10. [2506'arXiv] | MedSeg-R: Reasoning Segmentation in Medical Images with Multimodal Large Language Models | [`[paper]`](https://arxiv.org/abs/2506.10465) 
11. [2506'arXiv] | Lingshu: A Generalist Foundation Model for Unified Multimodal Medical Understanding and Reasoning | [`[paper]`](https://arxiv.org/abs/2506.07044) | [`[code]`](https://alibaba-damo-academy.github.io/lingshu/) 
12. [2505'arXiv] | AOR: Anatomical Ontology-Guided Reasoning for Medical Large Multimodal Model in Chest X-Ray Interpretation | [`[paper]`](https://arxiv.org/abs/2505.02830) | [`[code]`](https://github.com/Liqq1/AOR) 
13. [2505'arXiv] | Elicit and Enhance: Advancing Multimodal Reasoning in Medical Scenarios | [`[paper]`](https://arxiv.org/abs/2505.23118) 
14. [2405'arXiv] | Inquire, Interact, and Integrate: A Proactive Agent Collaborative Framework for Zero-Shot Multimodal Medical Reasoning | [`[paper]`](https://arxiv.org/abs/2405.11640) 

## 3. General Multimodal Reasoning Models <div id = "s3"></div>

1. [2504'arXiv] | VLM-R1: A Stable and Generalizable R1-style Large Vision-Language Model | [`[paper]`](https://arxiv.org/abs/2504.07615) | [`[code]`](https://github.com/om-ai-lab/VLM-R1) 
2. [2503'arXiv] | Vision-R1: Incentivizing Reasoning Capability in Multimodal Large Language Models | [`[paper]`](https://arxiv.org/abs/2503.06749) | [`[code]`](https://github.com/Osilly/Vision-R1) 
3. [2504'arXiv] | Skywork R1V2: Multimodal Hybrid Reinforcement Learning for Reasoning | [`[paper]`](https://arxiv.org/abs/2504.16656) | [`[code]`](https://huggingface.co/Skywork/Skywork-R1V2-38B) 
4. [2503'arXiv] | Multimodal Chain-of-Thought Reasoning: A Comprehensive Survey | [`[paper]`](https://arxiv.org/abs/2503.12605) | [`[code]`](https://github.com/yaotingwangofficial/Awesome-MCoT) 
5. [2505'arXiv] | Perception, Reason, Think, and Plan: A Survey on Large Multimodal Reasoning Models | [`[paper]`](https://arxiv.org/abs/2505.04921) | [`[code]`](https://github.com/HITsz-TMG/Awesome-Large-Multimodal-Reasoning-Models) 
6. [2501'arXiv] | Can MLLMs Reason in Multimodality? EMMA: An Enhanced MultiModal Reasoning Benchmark | [`[paper]`](https://www.arxiv.org/abs/2501.05444) | [`[code]`](https://github.com/EMMA-Bench/EMMA) 
6. [2502'arXiv] | iVISPAR -- An Interactive Visual-Spatial Reasoning Benchmark for VLMs | [`[paper]`](https://arxiv.org/abs/2502.04413) | [`[code]`](https://github.com/SNOWTEAM2023/MedRAG) 
7. [2502'arXiv] | From Foresight to Forethought: VLM-In-the-Loop Policy Steering via Latent Alignment | [`[paper]`](https://arxiv.org/abs/2502.01828) | [`[code]`](https://yilin-wu98.github.io/forewarn/) 
8. [2502'arXiv] | SKI Models: Skeleton Induced Vision-Language Embeddings for Understanding Activities of Daily Living | [`[paper]`](https://arxiv.org/abs/2502.03459) | [`[code]`](https://github.com/thearkaprava/SKI-Models) 
9. [2506'arXiv] | MEXA: Towards General Multimodal Reasoning with Dynamic Multi-Expert Aggregation | [`[paper]`](https://arxiv.org/abs/2506.17113v1) | [`[code]`](https://github.com/Yui010206/MEXA) 

## ü•∞ Star History
[![Star History Chart](https://api.star-history.com/svg?repos=HovChen/Paper-List-for-Medical-Reasoning-Large-Language-Models&type=Date)](https://star-history.com/#HovChen/Paper-List-for-Medical-Reasoning-Large-Language-Models&Date)

[![](https://capsule-render.vercel.app/api?type=waving&height=170&color=0:5B83DE,100:6BCE9F&text=Back%20to%20Top&section=footer&fontSize=25&fontAlignY=70&fontColor=FFFFFF)
](#top)
